{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e9193ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9f5f708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spontaneous_intervals(\n",
    "    data_path,                   # path to behaviour .mat\n",
    "    file_id,                     # 'meas00' / 'meas01' ... or int (0 -> meas00)\n",
    "    output=\"frames\",             # 'frames' or 'time'\n",
    "    buffers=None,                # per-event guard bands (s): {name: (pre, post)}\n",
    "    verbose=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Return Nx2 spontaneous intervals for a SPECIFIC recording (row) in MasterN.\n",
    "\n",
    "    file_id:\n",
    "      - str like 'meas00', 'meas03', etc., or\n",
    "      - int like 0, 1, 2 (interpreted as meas00, meas01, meas02).\n",
    "    The corresponding video column uses 1-based numbering in the filename:\n",
    "      meas00 -> ..._01.mp4, meas01 -> ..._02.mp4, etc.\n",
    "    \"\"\"\n",
    "    # ---------- load and locate the correct row ----------\n",
    "    mat = loadmat(data_path, squeeze_me=False, struct_as_record=False)\n",
    "    master = mat[\"MasterN\"]     # (n_rows, 13) cell array\n",
    "\n",
    "    # desired mp4 index (1-based)\n",
    "    if isinstance(file_id, str):\n",
    "        m = re.search(r'(\\d+)$', file_id.strip())\n",
    "        if not m:\n",
    "            raise ValueError(f\"file_id '{file_id}' should end with digits (e.g., 'meas00').\")\n",
    "        meas_num = int(m.group(1))\n",
    "    else:\n",
    "        meas_num = int(file_id)\n",
    "    mp4_num = meas_num + 1  # '..._01.mp4' for meas00\n",
    "\n",
    "    # helpers to unwrap MATLAB cell strings\n",
    "    def to_str(x):\n",
    "        if isinstance(x, str):\n",
    "            return x\n",
    "        if isinstance(x, np.ndarray) and x.size == 1:\n",
    "            v = x.item()\n",
    "            return v if isinstance(v, str) else str(v)\n",
    "        return str(x)\n",
    "\n",
    "    # column indices (0-based): video=1, TimeStamps=5\n",
    "    video_col = 1\n",
    "    ts_col    = 5\n",
    "\n",
    "    row_idx = None\n",
    "    pat = re.compile(r'_(\\d+)\\.mp4$', re.IGNORECASE)\n",
    "    for r in range(master.shape[0]):\n",
    "        vid = to_str(master[r, video_col])\n",
    "        m = pat.search(vid)\n",
    "        if m and int(m.group(1)) == mp4_num:\n",
    "            row_idx = r\n",
    "            break\n",
    "    if row_idx is None:\n",
    "        raise ValueError(f\"No MasterN row found whose video filename ends with _{mp4_num:02d}.mp4 \"\n",
    "                         f\"(derived from file_id={file_id}).\")\n",
    "\n",
    "    # ---------- unwrap the 7x4 TimeStamps table for that row ----------\n",
    "    ts_cell = master[row_idx, ts_col]\n",
    "    ts_tbl = ts_cell\n",
    "    while isinstance(ts_tbl, np.ndarray) and ts_tbl.dtype == object and ts_tbl.size == 1:\n",
    "        ts_tbl = ts_tbl.item()\n",
    "    ts_tbl = np.array(ts_tbl, dtype=object).squeeze()   # (7,4)\n",
    "\n",
    "    def unquote(s):\n",
    "        if isinstance(s, str):\n",
    "            return s.strip(\"'\")\n",
    "        if isinstance(s, np.ndarray) and s.size == 1 and isinstance(s.item(), str):\n",
    "            return s.item().strip(\"'\")\n",
    "        return str(s)\n",
    "\n",
    "    def unwrap_2col(x):\n",
    "        a = x\n",
    "        while isinstance(a, np.ndarray) and a.dtype == object and a.size == 1:\n",
    "            a = a.item()\n",
    "        if isinstance(a, np.ndarray) and a.ndim == 2 and a.shape[1] >= 2 and a.dtype != object:\n",
    "            return a[:, :2].astype(float)\n",
    "        return np.empty((0,2), float)\n",
    "\n",
    "    names = [unquote(ts_tbl[r,0]) for r in range(ts_tbl.shape[0])]\n",
    "    try:\n",
    "        i_frames = names.index(\"Frames\")\n",
    "    except ValueError:\n",
    "        i_frames = [i for i,n in enumerate(names) if \"Frames\" in n][0]\n",
    "\n",
    "    frames_td = unwrap_2col(ts_tbl[i_frames, 2])  # (n_frames, 2): [time, dt]\n",
    "    frame_times_beh = frames_td[:,0].astype(float)\n",
    "    fps = 1.0 / np.median(frames_td[:,1]) if np.all(frames_td[:,1] > 0) else 1.0/np.median(np.diff(frame_times_beh))\n",
    "\n",
    "    # ---------- parameters ----------\n",
    "    min_len_s  = 0.5\n",
    "    min_len_fr = int(np.ceil(min_len_s * fps))\n",
    "\n",
    "    default_buffers = {\n",
    "        \"Vis2\": (0.75, 1.00),\n",
    "        \"Con\" : (0.25, 0.50),\n",
    "        \"TOs2\": (0.25, 0.25),\n",
    "        \"Lik\" : (0.10, 0.10),\n",
    "        \"Rew\" : (0.20, 0.50),\n",
    "        \"ENT\" : (0.25, 0.25)\n",
    "    }\n",
    "    if buffers:\n",
    "        default_buffers.update(buffers)\n",
    "\n",
    "    # ---------- build busy intervals ----------\n",
    "    busy, event_counts = [], {}\n",
    "    for r, name in enumerate(names):\n",
    "        if name == \"Frames\":\n",
    "            continue\n",
    "        td = unwrap_2col(ts_tbl[r, 2])  # [time, duration]\n",
    "        if td.size == 0:\n",
    "            continue\n",
    "        starts = td[:,0]\n",
    "        ends   = td[:,0] + td[:,1]\n",
    "        pre, post = default_buffers.get(name, (0.10, 0.10))\n",
    "        arr = np.column_stack([starts - pre, ends + post])\n",
    "        busy.append(arr)\n",
    "        event_counts[name] = len(arr)\n",
    "\n",
    "    if not busy:\n",
    "        spont_times = np.array([[frame_times_beh[0], frame_times_beh[-1]]], float)\n",
    "        return _snap_and_filter(spont_times, frame_times_beh, output, min_len_fr)\n",
    "\n",
    "    busy_merged = _merge_intervals(np.vstack(busy))\n",
    "\n",
    "    # ---------- complement over movie span ----------\n",
    "    t0, t1 = frame_times_beh[0], frame_times_beh[-1]\n",
    "    spont_times = _complement_intervals(busy_merged, t0, t1)\n",
    "    result = _snap_and_filter(spont_times, frame_times_beh, output, min_len_fr)\n",
    "\n",
    "    if verbose:\n",
    "        total_dur = frame_times_beh[-1] - frame_times_beh[0]\n",
    "        spont_durs = np.diff(result, axis=1).squeeze()\n",
    "        spont_sec = spont_durs / fps if output == \"frames\" else spont_durs\n",
    "        n_spont = len(spont_sec)\n",
    "        mean_spont = np.mean(spont_sec) if n_spont > 0 else 0\n",
    "        max_spont = np.max(spont_sec) if n_spont > 0 else 0\n",
    "        spont_total = np.sum(spont_sec)\n",
    "        frac_spont = 100 * spont_total / total_dur\n",
    "\n",
    "        print(f\"[{data_path}] row={row_idx} file_id={file_id} (mp4 idx {mp4_num:02d}) fps≈{fps:.2f}\")\n",
    "        for name, count in event_counts.items():\n",
    "            print(f\"  {name:<6}: {count:5d} events\")\n",
    "        print(f\"Spontaneous: {n_spont} intervals | mean {mean_spont:.2f}s | max {max_spont:.2f}s \"\n",
    "              f\"| total {spont_total:.1f}s ({frac_spont:.1f}% of movie) \"\n",
    "              f\"| min kept {min_len_s:.2f}s (~{min_len_fr} fr)\")\n",
    "\n",
    "    return result\n",
    "\n",
    "# ---------- small utilities ----------\n",
    "def _merge_intervals(iv):\n",
    "    if iv.size == 0:\n",
    "        return np.empty((0,2), float)\n",
    "    iv = iv[np.argsort(iv[:,0])]\n",
    "    out = []\n",
    "    for s,e in iv:\n",
    "        if not out or s > out[-1][1]:\n",
    "            out.append([s,e])\n",
    "        else:\n",
    "            out[-1][1] = max(out[-1][1], e)\n",
    "    return np.array(out, float)\n",
    "\n",
    "def _complement_intervals(busy, t0, t1):\n",
    "    if busy.size == 0:\n",
    "        return np.array([[t0,t1]], float)\n",
    "    gaps, cur = [], t0\n",
    "    for s,e in busy:\n",
    "        if s > cur: gaps.append([cur, s])\n",
    "        cur = max(cur, e)\n",
    "        if cur >= t1: break\n",
    "    if cur < t1: gaps.append([cur, t1])\n",
    "    return np.array(gaps, float) if gaps else np.empty((0,2), float)\n",
    "\n",
    "def _snap_and_filter(spont_times, frame_times_beh, output, min_len_fr):\n",
    "    ft = frame_times_beh\n",
    "    start_idx = np.searchsorted(ft, spont_times[:,0], side=\"left\")\n",
    "    end_idx   = np.searchsorted(ft, spont_times[:,1], side=\"right\") - 1\n",
    "    start_idx = np.clip(start_idx, 0, len(ft)-1)\n",
    "    end_idx   = np.clip(end_idx,   -1, len(ft)-1)\n",
    "\n",
    "    keep = (end_idx - start_idx + 1) >= min_len_fr\n",
    "    start_idx, end_idx = start_idx[keep], end_idx[keep]\n",
    "    if start_idx.size == 0:\n",
    "        return np.empty((0,2), int) if output==\"frames\" else np.empty((0,2), float)\n",
    "\n",
    "    if output == \"frames\":\n",
    "        return np.column_stack([start_idx, end_idx + 1]).astype(int)  # half-open\n",
    "    return np.column_stack([ft[start_idx], ft[end_idx]]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b17c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_state_intervals(\n",
    "    csv_path,\n",
    "    date,                  # e.g., 240510 (int or str)\n",
    "    file_id,               # e.g., 'meas00'\n",
    "    short_run_threshold=3, # ≤ this many trials becomes \"unclear\" (internal runs only)\n",
    "    verbose=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Build engaged / attrition / unclear intervals from a TrialInfo CSV.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    {'engaged': Nx2, 'attrition': Mx2, 'unclear': Kx2}  # times in seconds\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Filter to Date & File (compare as strings to be forgiving about types)\n",
    "    sub = df[(df['Date'].astype(str) == str(date)) & (df['File'].astype(str) == str(file_id))].copy()\n",
    "\n",
    "    # Drop invalid trials and errors\n",
    "    sub = sub[(sub['ValidTrial?'] == True) & (sub['TrialType'] != 'Error (0)')]\n",
    "\n",
    "    if sub.empty:\n",
    "        out = {'engaged': np.empty((0,2)), 'attrition': np.empty((0,2)), 'unclear': np.empty((0,2))}\n",
    "        if verbose:\n",
    "            print(f\"No valid trials for Date={date}, File={file_id}.\")\n",
    "        return out\n",
    "\n",
    "    # Extract time & state, sorted by time\n",
    "    times = pd.to_numeric(sub['BFMTime']).to_numpy()\n",
    "    attr  = sub['Attrition?'].astype(int).to_numpy()\n",
    "    order = np.argsort(times)\n",
    "    times, attr = times[order], attr[order]\n",
    "\n",
    "    # Run-length encode Attrition?\n",
    "    runs = []\n",
    "    cur = attr[0]\n",
    "    start = 0\n",
    "    for i in range(1, len(attr)):\n",
    "        if attr[i] != cur:\n",
    "            runs.append((cur, start, i-1))  # (label, i0, i1)\n",
    "            cur, start = attr[i], i\n",
    "    runs.append((cur, start, len(attr)-1))\n",
    "\n",
    "    # Relabel short INTERNAL runs (≤ threshold) as unclear (label 2)\n",
    "    labeled = []\n",
    "    for j, (lab, i0, i1) in enumerate(runs):\n",
    "        length = i1 - i0 + 1\n",
    "        is_internal = (j > 0) and (j < len(runs)-1)\n",
    "        if is_internal and length <= short_run_threshold:\n",
    "            labeled.append((2, i0, i1))  # unclear\n",
    "        else:\n",
    "            labeled.append((lab, i0, i1))  # 0 engaged, 1 attrition\n",
    "\n",
    "    # Convert to [start_time, end_time] intervals\n",
    "    buckets = {0: [], 1: [], 2: []}\n",
    "    for lab, i0, i1 in labeled:\n",
    "        t_start = times[i0]\n",
    "        t_end   = times[i1]  # end at THIS run's last trial time (creates a gap to next run)\n",
    "        if t_end > t_start:\n",
    "            buckets[lab].append([t_start, t_end])\n",
    "\n",
    "    out = {\n",
    "        'engaged'  : np.array(buckets[0], dtype=float),\n",
    "        'attrition': np.array(buckets[1], dtype=float),\n",
    "        'unclear'  : np.array(buckets[2], dtype=float),\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        def stats(arr):\n",
    "            if len(arr) == 0:\n",
    "                return (0, 0.0, 0.0, 0.0)\n",
    "            d = arr[:,1] - arr[:,0]\n",
    "            return (len(arr), d.sum(), d.mean(), d.max())\n",
    "        nE,sE,mE,xE = stats(out['engaged'])\n",
    "        nA,sA,mA,xA = stats(out['attrition'])\n",
    "        nU,sU,mU,xU = stats(out['unclear'])\n",
    "        print(f\"[TrialInfo → intervals] Date={date}, File={file_id}\")\n",
    "        print(f\"  Engaged  : {nE:3d} intervals | total {sE:7.2f}s | mean {mE:5.2f}s | max {xE:5.2f}s\")\n",
    "        print(f\"  Attrition: {nA:3d} intervals | total {sA:7.2f}s | mean {mA:5.2f}s | max {xA:5.2f}s\")\n",
    "        print(f\"  Unclear  : {nU:3d} intervals | total {sU:7.2f}s | mean {mU:5.2f}s | max {xU:5.2f}s\")\n",
    "        print(f\"  Short-run threshold (internal only): ≤ {short_run_threshold} trials\")\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109433ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_spontaneous_intervals(\n",
    "    spont_times,           # Nx2 array of spontaneous intervals [t_start, t_end] (seconds)\n",
    "    state_intervals,       # dict from task_state_intervals_from_trialinfo_simple\n",
    "    verbose=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Classify spontaneous intervals as 'engaged' or 'attrition'\n",
    "    based on which task-state interval they fall inside.\n",
    "\n",
    "    Assumes:\n",
    "      - All spontaneous intervals are fully contained within (or outside) \n",
    "        the engaged/attrition intervals.\n",
    "      - Engaged and attrition intervals are non-overlapping and disjoint.\n",
    "      - All times are in the same (microscope) clock.\n",
    "    \"\"\"\n",
    "    engaged_iv   = np.asarray(state_intervals.get('engaged',   []), float)\n",
    "    attrition_iv = np.asarray(state_intervals.get('attrition', []), float)\n",
    "\n",
    "    engaged_spont, attrition_spont = [], []\n",
    "\n",
    "    for t0, t1 in spont_times:\n",
    "        # Check if this spontaneous interval lies fully inside any engaged interval\n",
    "        if np.any((t0 >= engaged_iv[:, 0]) & (t1 <= engaged_iv[:, 1])):\n",
    "            engaged_spont.append([t0, t1])\n",
    "        # Check if it's inside any attrition interval\n",
    "        elif np.any((t0 >= attrition_iv[:, 0]) & (t1 <= attrition_iv[:, 1])):\n",
    "            attrition_spont.append([t0, t1])\n",
    "        # Otherwise ignore (falls outside both)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    engaged_spont   = np.array(engaged_spont, dtype=float)\n",
    "    attrition_spont = np.array(attrition_spont, dtype=float)\n",
    "\n",
    "    if verbose:\n",
    "        def stats(arr):\n",
    "            if len(arr) == 0: return (0, 0.0, 0.0, 0.0)\n",
    "            d = arr[:,1] - arr[:,0]\n",
    "            return (len(arr), d.sum(), d.mean(), d.max())\n",
    "        nE,sE,mE,xE = stats(engaged_spont)\n",
    "        nA,sA,mA,xA = stats(attrition_spont)\n",
    "        print(f\"[Spontaneous classification]\")\n",
    "        print(f\"  Engaged  : {nE:3d} intervals | total {sE:7.2f}s | mean {mE:5.2f}s | max {xE:5.2f}s\")\n",
    "        print(f\"  Attrition: {nA:3d} intervals | total {sA:7.2f}s | mean {mA:5.2f}s | max {xA:5.2f}s\")\n",
    "\n",
    "    return engaged_spont, attrition_spont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09afe1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Z:/Voltage/VisualConsciousness/Analysis/VDT/cfm002mjr/20240510/BehaviorData.mat] row=2 file_id=meas01 (mp4 idx 02) fps≈157.18\n",
      "  Vis2  :    86 events\n",
      "  Con   :    24 events\n",
      "  TOs2  :    20 events\n",
      "  Lik   :   220 events\n",
      "  Rew   :    24 events\n",
      "  ENT   :    13 events\n",
      "Spontaneous: 92 intervals | mean 2.13s | max 5.22s | total 195.6s (42.4% of movie) | min kept 0.50s (~79 fr)\n",
      "[TrialInfo → intervals] Date=240510, File=meas01\n",
      "  Engaged  :   2 intervals | total  283.10s | mean 141.55s | max 240.26s\n",
      "  Attrition:   1 intervals | total  144.49s | mean 144.49s | max 144.49s\n",
      "  Unclear  :   0 intervals | total    0.00s | mean  0.00s | max  0.00s\n",
      "  Short-run threshold (internal only): ≤ 3 trials\n",
      "[Spontaneous classification]\n",
      "  Engaged  :  51 intervals | total  112.21s | mean  2.20s | max  5.08s\n",
      "  Attrition:  33 intervals | total   68.09s | mean  2.06s | max  5.22s\n"
     ]
    }
   ],
   "source": [
    "data_path = 'Z:/Voltage/VisualConsciousness/Analysis/VDT/cfm002mjr/20240510/BehaviorData.mat'\n",
    "spont_times = spontaneous_intervals(data_path, file_id=\"meas01\", output=\"time\", verbose=True)\n",
    "\n",
    "intervals = task_state_intervals(\n",
    "    \"trial_info/TrialInfo_cfm002mjr.csv\",\n",
    "    date=240510,\n",
    "    file_id=\"meas01\",\n",
    "    short_run_threshold=3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Classify spontaneous intervals by task state\n",
    "engaged_spont, attrition_spont = classify_spontaneous_intervals(spont_times, intervals, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eab406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "perception_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
