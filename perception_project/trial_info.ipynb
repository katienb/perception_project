{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generates and Checks the Trial Info Databases for Each Mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def behavior_path(mouse):\n",
    "    \"\"\"Returns the file path for behavioral data of the given mouse.\"\"\"\n",
    "    return '//tsclient/T7 Shield2/BehaviorDataBackup/VoltageMice/' + mouse + \"/PerceptualData_\" + mouse +\"_all.mat\"\n",
    "\n",
    "def movie_path(mouse, date, file):\n",
    "    \"\"\"Returns the file path for the corresponding movie data of a given mouse, date, and file.\"\"\"\n",
    "    return \"N:/GEVI_Wave/Analysis/Visual/\" + mouse + \"/20\" + str(date) + \"/\" + file + '/cG_unmixed_dFF.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_cell(cell):\n",
    "    \"\"\"Extracts the first element from a nested list or array, or returns None if empty.\"\"\"\n",
    "    # Handle nested lists or arrays\n",
    "    if isinstance(cell, (list, np.ndarray)):\n",
    "        return cell[0] if len(cell) > 0 else None  # Extract the first element if not empty\n",
    "    return cell\n",
    "\n",
    "def perceptual_category(df, data_behavior):\n",
    "    \"\"\"Categorizes trials based on perceptual contrast levels using binning.\"\"\"\n",
    "    percept_cats = pd.DataFrame(data_behavior[\"ConCrit\"])\n",
    "\n",
    "    # Extract min and max contrast values from percept_cats\n",
    "    min_values = percept_cats.iloc[1:, 0].to_list()  # First column (min values)\n",
    "    max_values = percept_cats.iloc[1:, 1].to_list()  # Second column (max values)\n",
    "    bins = [min_values[0]] + max_values  # Combine min start and max values to define bin edges\n",
    "\n",
    "    # Use pd.cut to categorize contrasts\n",
    "    categories = pd.cut(\n",
    "        df[\"Contrast\"],\n",
    "        bins=bins,  # Bin edges\n",
    "        labels=[1, 2, 3],  # Assign category labels\n",
    "        right=True,  # Include the right edge of bins\n",
    "        include_lowest=True # Include 0 for category 1\n",
    "    )\n",
    "\n",
    "    # Add the new column to the DataFrame\n",
    "    df.insert(5, \"PerceptualCat\", categories)\n",
    "    return df\n",
    "\n",
    "def categorize_trial(row):\n",
    "    \"\"\"Assigns each trial to a specific category based on behavioral conditions.\"\"\"\n",
    "    if (row[\"ReactTime\"] < 0.25) or (row[\"Enticed?\"] == 1) or ((row[\"Rewarded?\"] == 1) and (row[\"Consume?\"] == 0)):\n",
    "        return \"Error (0)\"\n",
    "\n",
    "    # Assign valid trials to categories\n",
    "    if row[\"Rewarded?\"] == 1 and row[\"Attrition?\"] == 0:\n",
    "        if row[\"PerceptualCat\"] == 1:\n",
    "            return \"False Alarm (1)\"\n",
    "        elif row[\"PerceptualCat\"] == 2:\n",
    "            return \"MC Hit (2)\"\n",
    "        elif row[\"PerceptualCat\"] == 3:\n",
    "            return \"HC Hit (3)\"\n",
    "    \n",
    "    if row[\"Rewarded?\"] == 0 and row[\"Attrition?\"] == 0:\n",
    "        if row[\"PerceptualCat\"] == 1:\n",
    "            return \"Correct Rejection (4)\"\n",
    "        elif row[\"PerceptualCat\"] == 2:\n",
    "            return \"MC Miss (5)\"\n",
    "        elif row[\"PerceptualCat\"] == 3:\n",
    "            return \"Incorrect Reject (6)\"\n",
    "\n",
    "    if row[\"Rewarded?\"] == 0 and row[\"Attrition?\"] == 1:\n",
    "        if row[\"PerceptualCat\"] == 1:\n",
    "            return \"LC No Report (7)\"\n",
    "        elif row[\"PerceptualCat\"] == 2:\n",
    "            return \"MC No Report (8)\"\n",
    "        elif row[\"PerceptualCat\"] == 3:\n",
    "            return \"HC No Report (9)\"\n",
    "    \n",
    "    return \"Uncategorized\"\n",
    "\n",
    "def trial_category(df, print_results=False):\n",
    "    \"\"\"Classifies trials into behavioral categories and optionally prints a summary.\"\"\"\n",
    "    # Apply function to each row\n",
    "\n",
    "    df.loc[(df['Attrition?'] == 1) & (df['Rewarded?'] == 1), 'Attrition?'] = 0\n",
    "\n",
    "    df[\"TrialType\"] = df.apply(categorize_trial, axis=1)\n",
    "\n",
    "    if print_results:\n",
    "        # Print summary\n",
    "        print(\"\\nTrial Type Summary:\")\n",
    "        summary = df[\"TrialType\"].value_counts()\n",
    "        for category, count in summary.items():\n",
    "            print(f\"{category}: {count} trials\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def map_recording_files(df):\n",
    "    \"\"\"Maps recording file numbers to each trial based on mouse and date.\"\"\" \n",
    "    base_path = \"//tsclient/T7 Shield2/BehaviorDataBackup/VoltageMice/\"\n",
    "    recording_file_map = {}\n",
    "\n",
    "    # Identify unique (mouse, date) pairs\n",
    "    unique_pairs = df[[\"AnimalCode\", \"Date\"]].drop_duplicates()\n",
    "\n",
    "    for _, row in unique_pairs.iterrows():\n",
    "        mouse = row[\"AnimalCode\"]\n",
    "        date = row[\"Date\"]\n",
    "        mat_path = f\"{base_path}{mouse}/Volt_{date}.mat\"\n",
    "\n",
    "        try:\n",
    "            # Load the MATLAB file\n",
    "            mat_data = loadmat(mat_path, struct_as_record=False, squeeze_me=True)\n",
    "            \n",
    "            # Extract the 'RESULTS' table\n",
    "            results = mat_data[\"RESULTS\"]\n",
    "            \n",
    "            # Extract the file numbers column\n",
    "            file_numbers = results[1:, 4]  # Column 5 (index 4) contains file numbers\n",
    "            \n",
    "            # Create a mapping of (mouse, date) -> ordered file numbers\n",
    "            recording_file_map[(mouse, date)] = list(file_numbers)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {mat_path}: {e}\")\n",
    "            recording_file_map[(mouse, date)] = None  # Store None if loading fails\n",
    "\n",
    "    # Map the correct file number to each row in df\n",
    "    def get_recording_file_num(row):\n",
    "        file_list = recording_file_map.get((row[\"AnimalCode\"], row[\"Date\"]), [])\n",
    "        if file_list and row[\"Recording\"] <= len(file_list):\n",
    "            return file_list[row[\"Recording\"] - 1]  # Adjust for zero-indexing\n",
    "        return None  # Return None if something is missing\n",
    "\n",
    "    df[\"File\"] = df.apply(get_recording_file_num, axis=1) - 1\n",
    "    df[\"File\"] = 'meas0' + df[\"File\"].astype(str)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Add column for trialID\n",
    "def trial_ID(df, mouse):\n",
    "    \"\"\"Generates a unique TrialID for each trial in the DataFrame.\"\"\"\n",
    "    df['TrialID'] = 'Visual/' + str(mouse) + '/20' + df['Date'].astype(str) + '/' + df['File'] + '/trial' + df['Trial'].astype(str).str.zfill(3)\n",
    "    return df\n",
    "\n",
    "def extract_specs(filepath):\n",
    "    \"\"\"Extracts FPS, time origin, and movie length from an HDF5 file.\"\"\"\n",
    "    with h5py.File(filepath, 'r') as mov_file:\n",
    "        specs = mov_file[\"specs\"]\n",
    "        fps = specs[\"fps\"][()][0][0]\n",
    "        timeorigin = specs[\"timeorigin\"][()][0][0]\n",
    "        movie_length = mov_file[\"mov\"].shape[0]\n",
    "    return fps, timeorigin, movie_length\n",
    "\n",
    "def compute_delays_and_bfm_times(df):\n",
    "    \"\"\" Computes delays and BFM times for each unique (Date, AnimalCode, Recording) combination, adds columns do df \"\"\"\n",
    "\n",
    "    basePath = '//tsclient/T7 Shield2/BehaviorDataBackup/VoltageMice/'\n",
    "    # Initialize dictionaries to cache delays and specs\n",
    "    delay_cache = {}\n",
    "    specs_cache = {}\n",
    "\n",
    "    # Find unique (Date, AnimalCode, Recording) combinations\n",
    "    unique_pairs = df[[\"Date\", \"AnimalCode\", \"Recording\", \"File\"]].drop_duplicates()\n",
    "\n",
    "    for _, row in unique_pairs.iterrows():\n",
    "        date = row[\"Date\"]\n",
    "        mouse = row[\"AnimalCode\"]\n",
    "        recording = row[\"Recording\"]\n",
    "        file = row[\"File\"]\n",
    "\n",
    "        # Compute delay\n",
    "        path2 = f\"{basePath}{mouse}/Volt_{date}_processed.mat\"\n",
    "        data2 = loadmat(path2)\n",
    "        df2 = pd.DataFrame(data2[\"MasterN\"]).map(lambda x: x[0] if isinstance(x, np.ndarray) and x.size > 0 else x)\n",
    "        df2.columns = df2.iloc[0]  \n",
    "        df2 = df2[1:]  \n",
    "        delayEstimates = df2['FrameAlignmentInfo'][recording][0][0]\n",
    "        delay = np.mean(delayEstimates)\n",
    "        delay_cache[(date, mouse, recording)] = delay\n",
    "\n",
    "        # Extract movie specs\n",
    "        filepath = movie_path(mouse, date, file)\n",
    "        fps, timeorigin, movie_length = extract_specs(filepath)\n",
    "        specs_cache[(date, mouse, recording)] = (fps, timeorigin, movie_length)\n",
    "\n",
    "    # Map delays and specs back to the original DataFrame\n",
    "    df[\"Delay\"] = df.apply(lambda row: delay_cache.get((row[\"Date\"], row[\"AnimalCode\"], row[\"Recording\"])), axis=1)\n",
    "    df[\"BFMTime\"] = df.apply(\n",
    "        lambda row: row[\"Time\"] - row[\"Delay\"] - int(specs_cache[(row[\"Date\"], row[\"AnimalCode\"], row[\"Recording\"])] [1].item()) / specs_cache[(row[\"Date\"], row[\"AnimalCode\"], row[\"Recording\"])][0].item(),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Determine the validity of each trial\n",
    "    df[\"ValidTrial?\"] = df.apply(\n",
    "        lambda row: 0 <= row[\"BFMTime\"] <= specs_cache.get((row[\"Date\"], row[\"AnimalCode\"], row[\"Recording\"]), (0, 0, 0))[2] / specs_cache.get((row[\"Date\"], row[\"AnimalCode\"], row[\"Recording\"]), (1, 1, 1))[0].item(),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "def filter_vdt_trials(df, xlsx_path):\n",
    "    \"\"\"\n",
    "    Filters trials from df to include only those where the corresponding recording has Task = 'VDT'.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): The trial dataframe containing 'Date', 'File', and 'AnimalCode'.\n",
    "    - xlsx_path (str): Path to the xlsx file.\n",
    "    - sheet_name (str): The name of the sheet containing recording metadata.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: The filtered dataframe containing only trials with Task = 'VDT'.\n",
    "    \"\"\"\n",
    "\n",
    "    recording_info = pd.read_excel(xlsx_path, sheet_name=\"Sheet1\")\n",
    "\n",
    "    df2 = df.copy()\n",
    "\n",
    "    df2[\"Date\"] = df2[\"Date\"].astype(str)\n",
    "    recording_info[\"Date\"] = recording_info[\"Date\"].astype(str).str[2:]  # Convert YYYYMMDD → YYMMDD\n",
    "    recording_info = recording_info.rename(columns={\"Animal\": \"AnimalCode\"})\n",
    "    recording_info[\"AnimalCode\"] = recording_info[\"AnimalCode\"].apply(lambda x: x if x.endswith(\"mjr\") else x + \"mjr\")\n",
    "\n",
    "    #Merge df with the xlsx data to bring in the Task column\n",
    "    merged_df = df2.merge(\n",
    "        recording_info,\n",
    "        left_on=[\"AnimalCode\", \"Date\", \"File\"],\n",
    "        right_on=[\"AnimalCode\", \"Date\", \"File\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Identify recordings where Task is not 'VDT'\n",
    "    flagged_recordings = merged_df.loc[merged_df[\"Task\"] != \"VDT\", [\"AnimalCode\", \"Date\", \"File\"]].drop_duplicates()\n",
    "\n",
    "    # Identify recordings missing from the xlsx file\n",
    "    missing_recordings = merged_df.loc[merged_df[\"Task\"].isna(), [\"AnimalCode\", \"Date\", \"File\"]].drop_duplicates()\n",
    "\n",
    "    # Print missing recordings\n",
    "    if not missing_recordings.empty:\n",
    "        print()\n",
    "        print(\"The following recordings were not found in the xlsx file:\")\n",
    "        print(missing_recordings.to_string(index=False))\n",
    "\n",
    "    # Print flagged recordings\n",
    "    if not flagged_recordings.empty:\n",
    "        print()\n",
    "        print(\"The following recordings were flagged for removal (Task != 'VDT'):\")\n",
    "        print(flagged_recordings.to_string(index=False))\n",
    "\n",
    "    # # Keep only trials where Task is 'VDT'\n",
    "    merged_df = merged_df[merged_df[\"Task\"] == \"VDT\"].copy()\n",
    "    merged_df.drop(columns=['Record#', 'identifier', 'Task', 'Active', 'VDT Behavior Quality.1'], inplace=True)\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "def gen_trial_info(mouse, days_to_omit=None):\n",
    "    \"\"\"\n",
    "    Generates a DataFrame containing trial information for a given mouse:\n",
    "    Processes behavioral data, categorizes trials, maps recording files,\n",
    "    computes timing information, and filters trials based on external logs.\n",
    "    Args:\n",
    "    - mouse (str): Identifier for the mouse.\n",
    "    - days_to_omit (list of ints): Days for which to remove all trials from dataframe\n",
    "    Returns:\n",
    "    - pd.DataFrame: Processed trial information with relevant columns.\n",
    "    \"\"\"\n",
    "    path_behavior = behavior_path(mouse)\n",
    "    data_behavior = loadmat(path_behavior)\n",
    "    df = pd.DataFrame(data_behavior[\"TrialInfo\"]).map(flatten_cell).map(flatten_cell)\n",
    "\n",
    "    # Set the second row as the header (column names)\n",
    "    df.columns = df.iloc[0]                    # Assign the second row as column names\n",
    "    df = df[1:]                                # Remove the first row (now redundant)\n",
    "\n",
    "    # Omit days with missing files or invalid data\n",
    "    if days_to_omit:\n",
    "        df = df[~df[\"Date\"].isin(days_to_omit)]\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)    # Reset the index to start from 0\n",
    "    df = df.rename(columns={\"Recording#\": \"Recording\"})\n",
    "\n",
    "    df = perceptual_category(df, data_behavior)\n",
    "    df = trial_category(df, print_results=True)\n",
    "    df = map_recording_files(df)\n",
    "    df = trial_ID(df, mouse)\n",
    "    df = compute_delays_and_bfm_times(df)\n",
    "    \n",
    "    xlsx_path = \"//tsclient/T7 Shield2/BehaviorDataBackup/VoltageMice/AllVoltage/RecordingLogsVoltage.xlsx\"\n",
    "    df = filter_vdt_trials(df, xlsx_path)\n",
    "\n",
    "    # Rearrange columns\n",
    "    order = ['TrialID', 'TrialType', 'AnimalCode', 'Date', 'Recording', 'File', 'Time', 'BFMTime', 'ValidTrial?', \n",
    "             'Duration', 'Contrast', 'PerceptualCat', 'ReactTime', 'Rewarded?', 'Enticed?', 'Seen?', 'Consume?', \n",
    "             'Attrition?', 'EngagementScore', 'EngagementScore_S20', 'VDT Behavior Quality']\n",
    "    df = df[[col for col in order if col in df.columns]]    # Reorder the DataFrame columns\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ttl_trace(df, fps, total_frames, date, file):\n",
    "    \"\"\"\n",
    "    Generates a TTL trace (1 for stimulus on, 0 for stimulus off) for each frame in the movie.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing 'BFMTime', 'Duration', and 'Date'.\n",
    "    - fps (float): Frames per second of the movie.\n",
    "    - total_frames (int): Total number of frames in the movie.\n",
    "    - date (int or str): Date to filter trials (e.g., 240506).\n",
    "    - file (str): file name - formatted as meas0#\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: TTL trace with 1 (stimulus on) and 0 (stimulus off), one value per frame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter the dataframe to include only trials for the given date\n",
    "    filtered_df = df[df[\"Date\"].astype(str) == str(date)]\n",
    "    filtered_df = filtered_df[filtered_df[\"File\"] == file]\n",
    "    filtered_df = filtered_df[filtered_df[\"ValidTrial?\"] == 1]\n",
    "\n",
    "    # Initialize the TTL trace with zeros (one entry per frame)\n",
    "    ttl_trace = np.zeros(total_frames, dtype=int)\n",
    "\n",
    "    # Loop through each trial in the filtered dataframe\n",
    "    for _, trial in filtered_df.iterrows():\n",
    "        # Compute the start and end frame indices for this trial\n",
    "        start_frame = int(trial[\"BFMTime\"] * fps)   # Convert BFMTime to frame index\n",
    "        end_frame = int((trial[\"BFMTime\"] + trial[\"Duration\"]) * fps)  # Duration in frames\n",
    "\n",
    "        # Set the frames for this trial to 1 (stimulus on)\n",
    "        ttl_trace[start_frame:end_frame] = 1\n",
    "\n",
    "    return ttl_trace\n",
    "\n",
    "def get_ttl_trace(timestamps_table, timestamps_table_names, timeorigin, timebinning=1):\n",
    "    \"\"\"\n",
    "    Extracts the TTL trace from the movie specs.\n",
    "\n",
    "    Args:\n",
    "    - timestamps_table (np.ndarray): Timestamps table containing TTL data.\n",
    "    - timestamps_table_names (np.ndarray): Column names for the timestamps table.\n",
    "    - timeorigin (int): Starting index for the TTL signal.\n",
    "    - timebinning (int, optional): Time binning factor for downsampling (default: 1).\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Extracted TTL signal.\n",
    "    \"\"\"\n",
    "  \n",
    "    # Get the column index for 'behavior_ttl'\n",
    "    ttl_column = timestamps_table_names.index(\"behavior_ttl\")\n",
    "\n",
    "    # Extract the raw TTL signal starting from `timeorigin`\n",
    "    ttl_signal_raw = timestamps_table[ttl_column, int(timeorigin):]\n",
    "\n",
    "    # Apply binning if `timebinning` is greater than 1\n",
    "    if timebinning > 1:\n",
    "        # Ensure the length of ttl_signal_raw is divisible by timebinning\n",
    "        trimmed_length = len(ttl_signal_raw) - (len(ttl_signal_raw) % timebinning)\n",
    "        ttl_signal_raw = ttl_signal_raw[:trimmed_length]\n",
    "        \n",
    "        # Reshape, average over bins, and round the result\n",
    "        ttl_signal = np.round(np.mean(ttl_signal_raw.reshape(-1, timebinning), axis=1))\n",
    "    else:\n",
    "        ttl_signal = ttl_signal_raw\n",
    "\n",
    "    return ttl_signal\n",
    "\n",
    "def check_ttl_alignment_file(df, mouse, date, file, tolerance=5, plot_all=False, plot_if_misaligned=True):\n",
    "    \"\"\"\n",
    "    Checks if the TTL traces from the movie and behavioral data are aligned for one file.\n",
    "\n",
    "    Args:\n",
    "    - ttl_movie (np.ndarray): TTL trace extracted from the movie.\n",
    "    - ttl_df (np.ndarray): TTL trace generated from behavioral data.\n",
    "    - tolerance (int, optional): Allowed frame difference for alignment. Default is 5.\n",
    "    - plot (bool, optional): Wether to plot both traces for comparison (default is False)\n",
    "\n",
    "    Returns:\n",
    "    - str: \"Aligned\" if all onset/offset differences are within tolerance, else \"Misaligned\".\n",
    "    \"\"\"\n",
    "    result = 'Aligned'\n",
    "\n",
    "    path_movie = movie_path(mouse, date, file)\n",
    "\n",
    "    with h5py.File(path_movie, 'r') as mov_file:\n",
    "        print(f\"Loading {path_movie}\")\n",
    "        specs = mov_file[\"specs\"]\n",
    "        fps = specs[\"fps\"][()][0][0][0]\n",
    "        timeorigin = specs[\"timeorigin\"][()][0][0][0]\n",
    "        timebinning = specs[\"timebinning\"][()][0][0]\n",
    "        timestamps_table = specs[\"extra_specs\"][\"timestamps_table\"][()].squeeze()\n",
    "        timestamps_table_names = specs[\"extra_specs\"][\"timestamps_table_names\"][()]\n",
    "        timestamps_table_names = b''.join(timestamps_table_names.flatten()).decode(\"utf-8\").split(';')\n",
    "\n",
    "    ttl_movie = get_ttl_trace(timestamps_table, timestamps_table_names, timeorigin, timebinning)\n",
    "    ttl_df = generate_ttl_trace(df, fps, len(ttl_movie), date, file)\n",
    "\n",
    "    # Find stimulus ONSET (0 -> 1) and OFFSET (1 -> 0) frames for both traces\n",
    "    onsets_movie = np.where(np.diff(ttl_movie) == 1)[0] \n",
    "    offsets_movie = np.where(np.diff(ttl_movie) == -1)[0] \n",
    "    onsets_df = np.where(np.diff(ttl_df) == 1)[0] \n",
    "    offsets_df = np.where(np.diff(ttl_df) == -1)[0] \n",
    "\n",
    "    # Removie movie stimulus from before or after behavior ttl trace\n",
    "    onsets_movie = onsets_movie[\n",
    "        (onsets_movie >= onsets_df[0] - 10) & (onsets_movie <= onsets_df[-1] + 10)]\n",
    "    offsets_movie = offsets_movie[\n",
    "        (offsets_movie >= offsets_df[0] - 10) & (offsets_movie <= offsets_df[-1] + 10)]\n",
    "\n",
    "    # Ensure equal number of onsets and offsets in both traces\n",
    "    if len(onsets_movie) != len(onsets_df) or len(offsets_movie) != len(offsets_df):\n",
    "        print(f\"ERROR for {mouse} {date} {file}: Mismatch in number of stimuli: {len(onsets_movie)} in movie, {len(onsets_df)} in df\")\n",
    "        result = 'Mismatch Number of Stimuli'\n",
    "        return result\n",
    "\n",
    "    # Compute frame differences for onsets and offsets\n",
    "    onset_diff = np.abs(onsets_movie - onsets_df)\n",
    "    offset_diff = np.abs(offsets_movie - offsets_df)\n",
    "\n",
    "    # Check if all differences are within tolerance\n",
    "    if (onset_diff > tolerance).any() or (offset_diff > tolerance).any():\n",
    "        print(f\"ERROR for {mouse} {date} {file}: Some frame differences exceed tolerance of {tolerance} frames.\")\n",
    "        print(f\"Onset differences: {onset_diff}\")\n",
    "        print(f\"Offset differences: {offset_diff}\")\n",
    "        result = 'Misaligned'\n",
    "\n",
    "    if plot_all or (plot_if_misaligned and result == 'Misaligned'):\n",
    "        if len(ttl_movie) > 10000:\n",
    "            plt.plot(ttl_movie[0:10000])\n",
    "            plt.plot(ttl_df[0:10000], ls='--')\n",
    "        else:\n",
    "            plt.plot(ttl_movie[0:min(len(ttl_movie), len(ttl_df))])\n",
    "            plt.plot(ttl_df[0:min(len(ttl_movie), len(ttl_df))], ls='--')\n",
    "        plt.legend([\"Movie\", \"Behavioral Data\"], loc=1)\n",
    "        plt.xlabel(\"Frame\")\n",
    "        plt.show()\n",
    "        plt.plot(ttl_movie[offsets_movie[0]-10:offsets_movie[0]+10])\n",
    "        plt.plot(ttl_df[offsets_movie[0]-10:offsets_movie[0]+10], ls='--')\n",
    "        plt.legend([\"Movie\", \"Behavioral Data\"], loc=1)\n",
    "        plt.xlabel(\"Frame (centered on first onset in movie)\")\n",
    "        plt.show()\n",
    "\n",
    "    return result\n",
    "\n",
    "def check_ttl_alignment_all(df, tolerance=10, plot_all=False, plot_if_misaligned=False, days_to_skip_testing=None):\n",
    "    \"\"\"\n",
    "    Checks TTL alignment for all unique recordings in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing the data.\n",
    "    - tolerance (int, optional): Allowed frame difference for alignment. Default is 5.\n",
    "    - plot_all (bool, optional): Whether to plot all traces. Default is False.\n",
    "    - plot_if_misaligned (bool, optional): Whether to plot traces if misaligned. Default is True.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    misaligned_recordings = []\n",
    "\n",
    "    # Extract unique combinations of 'AnimalCode', 'Date', and 'File'\n",
    "    unique_recordings = df[['AnimalCode', 'Date', 'File']].drop_duplicates()\n",
    "\n",
    "    # Don't test recordings in the days to skip testing\n",
    "    print(days_to_skip_testing)\n",
    "    if days_to_skip_testing:\n",
    "        unique_recordings = unique_recordings[~unique_recordings[\"Date\"].isin(days_to_skip_testing)]\n",
    "    print(unique_recordings)\n",
    "\n",
    "    # Iterate over each unique recording\n",
    "    for _, row in unique_recordings.iterrows():\n",
    "        mouse = row['AnimalCode']\n",
    "        date = row['Date']\n",
    "        file = row['File']\n",
    "\n",
    "        #print(f\"Checking alignment for Mouse: {mouse}, Date: {date}, File: {file}...\")\n",
    "        result  = check_ttl_alignment_file(df, mouse, date, file, tolerance, plot_all=False, plot_if_misaligned=True)\n",
    "\n",
    "        if result == 'Misaligned' or result == 'Mismatch Number of Stimuli':\n",
    "            misaligned_recordings.append((mouse, date, file))\n",
    "            df.loc[(df[\"AnimalCode\"] == mouse) & (df[\"Date\"] == date) & (df[\"File\"] == file), \"ValidTrial?\"] = False\n",
    "\n",
    "    # Summary of results\n",
    "    if not misaligned_recordings:\n",
    "        print(\"\\nMisaligned Recordings:\")\n",
    "        for mouse, date, file in misaligned_recordings:\n",
    "            print(f\"Mouse: {mouse}, Date: {date}, File: {file}\")\n",
    "    else :\n",
    "        print(\"\\nAll recordings are aligned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_files_exist(df):\n",
    "    \"\"\"\n",
    "    Checks if the movie files for all unique (mouse, date, recording) pairs exist.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame containing trial information.\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if all files exist, False if any are missing.\n",
    "    \"\"\"\n",
    "    # Identify unique (mouse, date, recording) pairs\n",
    "    recordings = df[[\"AnimalCode\", \"Date\", 'File']].drop_duplicates()\n",
    "    all_files_exist = True\n",
    "\n",
    "    for _, row in recordings.iterrows():\n",
    "        mouse = row[\"AnimalCode\"]\n",
    "        date = row[\"Date\"]\n",
    "        file = row['File']\n",
    "\n",
    "        path_to_check = movie_path(mouse, date, file)\n",
    "\n",
    "        if not os.path.exists(path_to_check):\n",
    "            print(\"Missing File: \", path_to_check)\n",
    "            all_files_exist = False\n",
    "\n",
    "    if all_files_exist:\n",
    "        print(\"All files exist\")\n",
    "    \n",
    "    return all_files_exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it Together: Generating, Checking and Saving Trial Info File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trial Type Summary:\n",
      "HC No Report (9): 510 trials\n",
      "MC No Report (8): 420 trials\n",
      "LC No Report (7): 299 trials\n",
      "HC Hit (3): 223 trials\n",
      "Error (0): 181 trials\n",
      "MC Miss (5): 118 trials\n",
      "MC Hit (2): 99 trials\n",
      "Correct Rejection (4): 94 trials\n",
      "Incorrect Reject (6): 55 trials\n",
      "False Alarm (1): 11 trials\n",
      "\n",
      "The following recordings were not found in the xlsx file:\n",
      "AnimalCode   Date   File\n",
      " cmm002mjr 231214 meas03\n",
      "\n",
      "The following recordings were flagged for removal (Task != 'VDT'):\n",
      "AnimalCode   Date   File\n",
      " cmm002mjr 231208 meas00\n",
      " cmm002mjr 231214 meas03\n",
      " cmm002mjr 231215 meas02\n",
      " cmm002mjr 240502 meas01\n",
      " cmm002mjr 240502 meas02\n",
      "Generated Dataframe, Now Checking\n",
      "None\n",
      "     AnimalCode    Date    File\n",
      "249   cmm002mjr  231212  meas00\n",
      "296   cmm002mjr  231212  meas01\n",
      "398   cmm002mjr  231212  meas02\n",
      "605   cmm002mjr  231213  meas01\n",
      "664   cmm002mjr  231213  meas02\n",
      "813   cmm002mjr  231213  meas03\n",
      "1011  cmm002mjr  231214  meas00\n",
      "1074  cmm002mjr  231214  meas01\n",
      "1420  cmm002mjr  231215  meas03\n",
      "Loading N:/GEVI_Wave/Analysis/Visual/cmm002mjr/20231212/meas00/cG_unmixed_dFF.h5\n",
      "Loading N:/GEVI_Wave/Analysis/Visual/cmm002mjr/20231212/meas01/cG_unmixed_dFF.h5\n",
      "Loading N:/GEVI_Wave/Analysis/Visual/cmm002mjr/20231212/meas02/cG_unmixed_dFF.h5\n",
      "Loading N:/GEVI_Wave/Analysis/Visual/cmm002mjr/20231213/meas01/cG_unmixed_dFF.h5\n",
      "Loading N:/GEVI_Wave/Analysis/Visual/cmm002mjr/20231213/meas02/cG_unmixed_dFF.h5\n",
      "Loading N:/GEVI_Wave/Analysis/Visual/cmm002mjr/20231213/meas03/cG_unmixed_dFF.h5\n",
      "Loading N:/GEVI_Wave/Analysis/Visual/cmm002mjr/20231214/meas00/cG_unmixed_dFF.h5\n",
      "Loading N:/GEVI_Wave/Analysis/Visual/cmm002mjr/20231214/meas01/cG_unmixed_dFF.h5\n",
      "Loading N:/GEVI_Wave/Analysis/Visual/cmm002mjr/20231215/meas03/cG_unmixed_dFF.h5\n",
      "\n",
      "Misaligned Recordings:\n",
      "All files exist\n"
     ]
    }
   ],
   "source": [
    "mouse = 'cmm002mjr'\n",
    "df = gen_trial_info(mouse)\n",
    "print('Generated Dataframe, Now Checking')\n",
    "check_ttl_alignment_all(df)\n",
    "check_files_exist(df)\n",
    "df.to_csv(f'trial_info/TrialInfo_{mouse}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
